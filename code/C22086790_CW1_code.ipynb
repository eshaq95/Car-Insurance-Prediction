{"cells":[{"cell_type":"markdown","id":"bdb4869c","metadata":{"id":"bdb4869c"},"source":["#### Student name: Eshaq Rahmani\n","#### Student number: 22086790\n"]},{"cell_type":"markdown","id":"0d6eeba8","metadata":{"id":"0d6eeba8"},"source":["# Data Exploration"]},{"cell_type":"markdown","id":"c98824e4","metadata":{"id":"c98824e4"},"source":["## 1. Get data"]},{"cell_type":"code","execution_count":null,"id":"b5069028","metadata":{"id":"b5069028"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split\n","\n","#Read the csv by loading the data into a pandas dataframe\n","df=pd.read_csv('CW1_data_202223.csv')\n","\n","\n","# We drop 'id' as it is useless for the ML model.\n","df = df.drop('id', axis=1)\n","\n","\n","# Separate the features and target\n","X = df.drop('Result', axis=1)\n","y = df['Result']\n","df.head(10)\n"]},{"cell_type":"markdown","id":"5d87885f","metadata":{"id":"5d87885f"},"source":["## 2. Clean AnnualPremium"]},{"cell_type":"code","execution_count":null,"id":"500e9afb","metadata":{"scrolled":true,"id":"500e9afb"},"outputs":[],"source":["# Clean the AnnualPremium column\n","# Define a custom function to parse the string to a float\n","def parse_amount(s):\n","    # Remove the leading and trailing white spaces\n","    s = s.strip()\n","\n","    # Remove the currency symbol\n","    s = s.replace(\"Â£\", \"\")\n","\n","    # Remove the commas\n","    s = s.replace(\",\", \"\")\n","\n","    # Convert the string to a float\n","    return float(s)\n","\n","# Use the apply() function to parse the 'amount' column\n","df['AnnualPremium'] = df['AnnualPremium'].apply(parse_amount)\n","df.head(5)"]},{"cell_type":"markdown","id":"d351ff18","metadata":{"id":"d351ff18"},"source":["## 3. Data description"]},{"cell_type":"markdown","id":"d4927b62","metadata":{"id":"d4927b62"},"source":["### 3.1 Data info"]},{"cell_type":"code","execution_count":null,"id":"eb21025f","metadata":{"scrolled":false,"id":"eb21025f"},"outputs":[],"source":["# Print information about the dataframe\n","df.info()\n"]},{"cell_type":"markdown","id":"c2a3a26f","metadata":{"id":"c2a3a26f"},"source":["### 3.2 Missing values exploration"]},{"cell_type":"code","execution_count":null,"id":"066215eb","metadata":{"id":"066215eb"},"outputs":[],"source":["# Missing values\n","missing_values = df.isnull().sum()\n","print(missing_values)"]},{"cell_type":"markdown","id":"8717406c","metadata":{"id":"8717406c"},"source":["### 3.3 Data describe - mean, std, quantiles"]},{"cell_type":"code","execution_count":null,"id":"f620a30f","metadata":{"scrolled":true,"id":"f620a30f"},"outputs":[],"source":["# Print summary statistics about the data\n","df.describe()"]},{"cell_type":"markdown","id":"0c55794b","metadata":{"id":"0c55794b"},"source":["## 4. Count plots"]},{"cell_type":"code","execution_count":null,"id":"a2dd4e98","metadata":{"scrolled":false,"id":"a2dd4e98"},"outputs":[],"source":["### Count plots for each CATEGORICAL feature and target variable ###\n","import plotly.express as px\n","from plotly.subplots import make_subplots\n","import plotly.graph_objs as go\n","import plotly.io as pio\n","\n","# setting Google color palette as default\n","pio.templates.default = \"seaborn\"\n","\n","\n","# Make subplots to align plots\n","fig = make_subplots(rows=3, cols=3, subplot_titles=(\"Gender\", \"HasDrivingLicense\", \"PastAccident \",\n","                                                    \"Switch\", 'VehicleAge' , 'Result' ,\n","                                                    'SalesChannelID', 'RegionID'))\n","\n","# Calculate the relative percentages for each count plot\n","\n","# Gender relative percentages\n","males = df[df['Gender'] == 'Male']['Gender'].count()\n","females = df[df['Gender'] == 'Female']['Gender'].count()\n","male_percentage = males / (males + females) * 100\n","female_percentage = females / (males + females) * 100\n","\n","# HasDrivingLicense relative percentages\n","has_driving_license = df[df['HasDrivingLicense'] == 1]['HasDrivingLicense'].count()\n","no_driving_license = df[df['HasDrivingLicense'] == 0]['HasDrivingLicense'].count()\n","has_driving_license_percentage = has_driving_license / (has_driving_license + no_driving_license) * 100\n","no_driving_license_percentage = no_driving_license / (has_driving_license + no_driving_license) * 100\n","\n","# PastAccident relative percentages\n","has_past_accident = df[df['PastAccident'] == 'Yes']['PastAccident'].count()\n","no_past_accident = df[df['PastAccident'] == 'No']['PastAccident'].count()\n","has_past_accident_percentage = has_past_accident / (has_past_accident + no_past_accident) * 100\n","no_past_accident_percentage = no_past_accident / (has_past_accident + no_past_accident) * 100\n","\n","# Switch relative percentages\n","switch_yes = df[df['Switch'] == 1]['Switch'].count()\n","switch_no = df[df['Switch'] == 0]['Switch'].count()\n","switch_yes_percentage = switch_yes / (switch_yes + switch_no) * 100\n","switch_no_percentage = switch_no / (switch_yes + switch_no) * 100\n","\n","# VehicleAge relative percentages\n","vehicle_age_old = df[df['VehicleAge'] == '< 1 Year']['VehicleAge'].count()\n","vehicle_age_med = df[df['VehicleAge'] == '1-2 Year']['VehicleAge'].count()\n","vehicle_age_new = df[df['VehicleAge'] == '> 2 Years']['VehicleAge'].count()\n","\n","vehicle_age_old_percentage = vehicle_age_old / (vehicle_age_old + vehicle_age_new + vehicle_age_med) * 100\n","vehicle_age_med_percentage = vehicle_age_med / (vehicle_age_med + vehicle_age_new + vehicle_age_old) * 100\n","vehicle_age_new_percentage = vehicle_age_new / (vehicle_age_new + vehicle_age_old + vehicle_age_med) * 100\n","\n","# Result relative percentages\n","result_yes = df[df['Result'] == 1]['Result'].count()\n","result_no = df[df['Result'] == 0]['Result'].count()\n","result_yes_percentage = result_yes / (result_yes + result_no) * 100\n","result_no_percentage = result_no / (result_yes + result_no) * 100\n","\n","\n","# Add traces to subplots\n","traces = [\n","    go.Bar(\n","        x=['Male', 'Female'],\n","        y=[\n","            len(df[df['Gender']=='Male']),\n","            len(df[df['Gender']=='Female'])\n","        ],\n","        name='Gender',\n","        text = [\n","            str(round(male_percentage, 2)) + '%',\n","            str(round(female_percentage, 2)) + '%'\n","        ],\n","        textposition='auto'\n","    ), go.Bar(\n","        x=['1', '0'],\n","        y=[\n","            len(df[df['HasDrivingLicense']==1]),\n","            len(df[df['HasDrivingLicense']==0])\n","        ],\n","        name='HasDrivingLicense',\n","        text = [\n","            str(round(has_driving_license_percentage, 2)) + '%',\n","            str(round(no_driving_license_percentage, 2)) + '%'\n","        ],\n","        textposition='auto'\n","    ), go.Bar(\n","        x=['Yes', 'No'],\n","        y=[\n","            len(df[df['PastAccident']=='Yes']),\n","            len(df[df['PastAccident']=='No'])\n","        ],\n","        name='PastAccident',\n","        text = [\n","            str(round(has_past_accident_percentage, 2)) + '%',\n","            str(round(no_past_accident_percentage, 2)) + '%'\n","        ],\n","        textposition='auto'\n","    ), go.Bar(\n","        x=['1', '0'],\n","        y=[\n","            len(df[df['Switch']==1]),\n","            len(df[df['Switch']==0])\n","        ],\n","        name='Switch',\n","        text = [\n","             str(round(switch_yes_percentage, 2)) + '%',\n","             str(round(switch_no_percentage, 2)) + '%'\n","        ],\n","        textposition='auto'\n","    ), go.Bar(\n","        x=['< 1 Year', '1-2 Year', '> 2 Years'],\n","        y=[\n","            len(df[df['VehicleAge']=='< 1 Year']),\n","            len(df[df['VehicleAge']=='1-2 Year']),\n","            len(df[df['VehicleAge']=='> 2 Years'])\n","        ],\n","        name='VehicleAge',\n","        text = [\n","            str(round(vehicle_age_old_percentage, 2)) + '%',\n","            str(round(vehicle_age_med_percentage, 2)) + '%',\n","            str(round(vehicle_age_new_percentage, 2)) + '%'\n","        ],\n","        textposition='auto'\n","    ), go.Bar(\n","        x=[1, 0],\n","        y=[\n","            len(df[df['Result']==1]),\n","            len(df[df['Result']==0])\n","        ],\n","        name='Result',\n","        text = [\n","            str(round(result_yes_percentage, 2)) + '%',\n","            str(round(result_no_percentage, 2)) + '%'\n","        ],\n","        textposition='auto'\n","    ), go.Histogram(\n","        x=df['SalesChannelID'],\n","        name='SalesChannelID'\n","    ), go.Histogram(\n","        x=df['RegionID'],\n","        name='RegionID'\n","    ),\n","\n","]\n","\n","for i in range(len(traces)):\n","    fig.append_trace(\n","        traces[i],\n","        (i // 3) + 1,\n","        (i % 3)  +1,)\n","\n","fig.update_layout(\n","    title_text='Count Plots',\n","    height=800,\n","    width=1000,\n","    showlegend=False)\n","\n","\n","fig.show()"]},{"cell_type":"markdown","id":"6483a7c5","metadata":{"id":"6483a7c5"},"source":["## 5. Pie charts"]},{"cell_type":"code","execution_count":null,"id":"797f2849","metadata":{"id":"797f2849"},"outputs":[],"source":["### Pie chart for each feature to check ratios ###\n","\n","# List of columns to include in the plot\n","columns_to_include = ['Gender', 'Switch', 'HasDrivingLicense', 'VehicleAge', 'PastAccident', 'Result']\n","\n","\n","column_names = df.columns\n","# Filter the list of column names to only include the specified columns\n","filtered_column_names = [column_name for column_name in column_names if column_name in columns_to_include]\n","\n","# Set the figure size\n","plt.figure(figsize=(15, 15))\n","\n","# Iterate over the filtered column names\n","for i, column_name in enumerate(filtered_column_names):\n","    # Get the counts of each value for the column\n","    counts = df[column_name].value_counts()\n","\n","    # Get the labels and values for the pie chart\n","    labels = counts.index\n","    values = counts.values\n","\n","    # Create a subplot\n","    plt.subplot(3, 3, i+1)\n","\n","    # Create the pie chart\n","    plt.pie(values, labels=labels, autopct='%1.1f%%')\n","\n","    # Add a title\n","    plt.title(column_name)\n","\n","# Show the plot\n","plt.show()\n","\n"]},{"cell_type":"markdown","id":"2c0509a0","metadata":{"id":"2c0509a0"},"source":["## 7. Count plots - Numerical"]},{"cell_type":"code","execution_count":null,"id":"9aa03b73","metadata":{"scrolled":false,"id":"9aa03b73"},"outputs":[],"source":["### Count plots for each NUMERICAL feature and target variable ###\n","\n","fig = make_subplots(rows=2, cols=2, subplot_titles=(\"Age\", \"AnnualPremium\", \"DaysSinceCreated\"))\n","\n","traces = [\n","    go.Histogram(\n","        x=df['Age'],\n","        name='Age'\n","    ),\n","    go.Histogram(\n","        x=df['AnnualPremium'],\n","        name='AnnualPremium'\n","    ),\n","\n","    go.Histogram(\n","        x=df['DaysSinceCreated'],\n","        name='DaysSinceCreated'\n","    ),\n","\n","]\n","\n","for i in range(len(traces)):\n","    fig.append_trace(\n","        traces[i],\n","        (i // 2) + 1,\n","        (i % 2)  + 1\n","    )\n","\n","fig.update_layout(\n","    title_text='Numerical Feature Distribution',\n","    height=800,\n","    width=1000,\n","    showlegend=False\n",")\n","\n","fig.show()\n","\n"]},{"cell_type":"markdown","id":"2ae0618a","metadata":{"id":"2ae0618a"},"source":["## 8. Box Plots"]},{"cell_type":"code","execution_count":null,"id":"5baf308c","metadata":{"scrolled":false,"id":"5baf308c"},"outputs":[],"source":["### Box plot to check for outliers ###\n","\n","import plotly.express as px\n","import plotly.graph_objs as go\n","\n","#Make subplots to align plots\n","fig = make_subplots(rows=2, cols=2, subplot_titles=(\"AnnualPremium\", \"Age\", \"DaysSinceCreated\"))\n","\n","#Annual Premium boxplot\n","annual_premium_boxplot = px.box(df, x=\"AnnualPremium\", labels={'AnnualPremium':'AnnualPremium'})\n","fig.add_trace(annual_premium_boxplot[\"data\"][0], row=1, col=1)\n","\n","#Age boxplot\n","age_boxplot = px.box(df, x=\"Age\", labels={'Age':'Age'})\n","fig.add_trace(age_boxplot[\"data\"][0], row=1, col=2)\n","\n","#Days Since Created boxplot\n","days_since_created_boxplot = px.box(df, x=\"DaysSinceCreated\", labels={'DaysSinceCreated':'DaysSinceCreated'})\n","fig.add_trace(days_since_created_boxplot[\"data\"][0], row=2, col=1)\n","\n","fig.update_layout(\n","    height=600,\n","    width=800\n",")\n","\n","\n","fig.show()"]},{"cell_type":"markdown","id":"7ffda7ae","metadata":{"id":"7ffda7ae"},"source":["### 8.1 Outlier count"]},{"cell_type":"code","execution_count":null,"id":"7fe7a2a2","metadata":{"scrolled":true,"id":"7fe7a2a2"},"outputs":[],"source":["### Finding number of outliers ###\n","_, ax = plt.subplots()\n","\n","bp = ax.boxplot(df[\"AnnualPremium\"])\n","outliers = [f.get_ydata() for f in bp[\"fliers\"]]\n","outlier_count = len(outliers[0])\n","\n","print(f\"Number of outliers: {outlier_count}\")"]},{"cell_type":"markdown","id":"c7c33a82","metadata":{"id":"c7c33a82"},"source":["## 9. Feature vs Result plot"]},{"cell_type":"markdown","id":"32f1de3e","metadata":{"id":"32f1de3e"},"source":["Change variable for analysis of different feature against Result"]},{"cell_type":"code","execution_count":null,"id":"99ca1cf4","metadata":{"id":"99ca1cf4"},"outputs":[],"source":["fig = px.histogram(df, \"Age\", color='Result', title='PastAccident Vs Result', width=600, height=400)\n","fig.show()"]},{"cell_type":"markdown","id":"fc346d10","metadata":{"id":"fc346d10"},"source":["# Data pre-processing"]},{"cell_type":"markdown","id":"515a63e5","metadata":{"id":"515a63e5"},"source":["## 2. Imputation"]},{"cell_type":"markdown","id":"2f016642","metadata":{"id":"2f016642"},"source":["### 2.1 Imputation with 'Missing', forward fill and mode"]},{"cell_type":"code","execution_count":null,"id":"84ec8a87","metadata":{"scrolled":false,"id":"84ec8a87"},"outputs":[],"source":["# from sklearn.impute import SimpleImputer\n","\n","# # Mapping Switch column where NaN is mapped 'Missing'\n","# df['Switch'] = df['Switch'].map(lambda x: 'Missing' if pd.isnull(x) else x)\n","\n","# # Mapping PastAccident column where NaN is mapped 'Missing'\n","# df['PastAccident'] = df['PastAccident'].map({'Yes': 1, 'No': 0, np.nan: 'Missing'})\n","\n","# # Forward fill the values in the \"age\" column\n","# df[\"Age\"].ffill(inplace=True)\n","\n","# # Gender mode imputation\n","# imputer = SimpleImputer(strategy='most_frequent') # Create an instance of the SimpleImputer class\n","# # Fit the imputer to the Gender column\n","# imputer.fit(df[['Gender']])\n","# # Transform the Gender column using the fitted imputer\n","# df['Gender'] = imputer.transform(df[['Gender']])\n","\n","\n","# # HasDrivingLicense mode imputation\n","# imputer = SimpleImputer(strategy='most_frequent') # Create an instance of the SimpleImputer class\n","# # Fit the imputer to the Gender column\n","# imputer.fit(df[['HasDrivingLicense']])\n","# # Transform the Gender column using the fitted imputer\n","# df['HasDrivingLicense'] = imputer.transform(df[['HasDrivingLicense']])\n","\n","\n","# # Forward fill the values in the \"age\" column\n","# df[\"VehicleAge\"].ffill(inplace=True)\n","# # Forward fill the values in the \"RegionID\" column\n","# df[\"RegionID\"].ffill(inplace=True)\n","# df"]},{"cell_type":"markdown","id":"f557b273","metadata":{"id":"f557b273"},"source":["### 2.2 Imputation with IterativeImputer (Bayesian estimator) - Best performance on Models!"]},{"cell_type":"code","execution_count":null,"id":"63197b1c","metadata":{"id":"63197b1c"},"outputs":[],"source":["from sklearn.experimental import enable_iterative_imputer\n","from sklearn.impute import IterativeImputer\n","\n","# # Ecoding features must be done for iterative imputer\n","# as it can not handle string inputs\n","\n","## Encoding\n","\n","mapping1 = {'Yes': 1, 'No': 0}\n","df['PastAccident'] = df['PastAccident'].map(mapping1)\n","# Mapping for Gender\n","mapping2 = {'Male': 1, 'Female': 0}\n","df['Gender'] = df['Gender'].map(mapping2)\n","\n","# Mapping for VehicleAge\n","df['VehicleAge'] = df['VehicleAge'].map({'< 1 Year': 0, '1-2 Year': 1, '> 2 Years': 2})\n","\n","\n","\n","# Create the imputer object\n","imputer = IterativeImputer(max_iter=10, random_state=0)\n","\n","# Impute the missing values\n","df_imputed = imputer.fit_transform(df)\n","\n","# The imputed dataset is returned as a numpy array, so you can convert it back to a Pandas DataFrame if needed\n","df = pd.DataFrame(df_imputed.round(), columns=df.columns)\n","df"]},{"cell_type":"markdown","id":"98d8740b","metadata":{"id":"98d8740b"},"source":["### 2.3 Imputation with KNNImputer"]},{"cell_type":"code","execution_count":null,"id":"100b37ab","metadata":{"id":"100b37ab"},"outputs":[],"source":["# from sklearn.impute import KNNImputer\n","\n","# # Create a KNNImputer object\n","# imputer = KNNImputer()\n","\n","# # Impute the missing values\n","# df_imputed = imputer.fit_transform(df)\n","\n","# # The imputed dataset is returned as a numpy array, so you can convert it back to a Pandas DataFrame if needed\n","# df = pd.DataFrame(df_imputed, columns=df.columns)\n","# df"]},{"cell_type":"markdown","id":"1e946a1b","metadata":{"id":"1e946a1b"},"source":["### 2.4 Checking distributions after imputation for evaluation"]},{"cell_type":"code","execution_count":null,"id":"c6b8dc01","metadata":{"id":"c6b8dc01"},"outputs":[],"source":["### Pie chart for each feature to check ratios ###\n","\n","# List of columns to include in the plot\n","columns_to_include = ['Gender', 'Switch', 'VehicleAge', 'PastAccident', 'Result']\n","\n","\n","column_names = df.columns\n","# Filter the list of column names to only include the specified columns\n","filtered_column_names = [column_name for column_name in column_names if column_name in columns_to_include]\n","\n","# Set the figure size\n","plt.figure(figsize=(15, 15))\n","\n","# Iterate over the filtered column names\n","for i, column_name in enumerate(filtered_column_names):\n","    # Get the counts of each value for the column\n","    counts = df[column_name].value_counts()\n","\n","    # Get the labels and values for the pie chart\n","    labels = counts.index\n","    values = counts.values\n","\n","    # Create a subplot\n","    plt.subplot(3, 3, i+1)\n","\n","    # Create the pie chart\n","    plt.pie(values, labels=labels, autopct='%1.1f%%')\n","\n","    # Add a title\n","    plt.title(column_name)\n","\n","# Show the plot\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"id":"d2f8605d","metadata":{"id":"d2f8605d"},"outputs":[],"source":["# Plot histogram of Feature vs Target Variable\n","fig = px.histogram(\n","    df,\n","    \"Age\",\n","    color='Result',\n","    nbins=100,\n","    title='Age & Result ditribution',\n","    width=700,\n","    height=500\n",")\n","\n","fig.show()"]},{"cell_type":"markdown","id":"5a63429b","metadata":{"id":"5a63429b"},"source":["## 3. Remove outliers and Feature Scaling"]},{"cell_type":"markdown","id":"59fdb507","metadata":{"id":"59fdb507"},"source":["### 3.1 Remove Outliers"]},{"cell_type":"code","execution_count":null,"id":"0e5387d6","metadata":{"id":"0e5387d6"},"outputs":[],"source":["# Check for outliers after imputation\n","\n","# Create a figure with three subplots arranged in a single row\n","fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(21, 5))\n","\n","# Plot the first boxplot\n","sns.boxplot(x=df[\"AnnualPremium\"], ax=ax1)\n","\n","# Plot the second boxplot\n","sns.boxplot(x=df[\"Age\"], ax=ax2)"]},{"cell_type":"code","execution_count":null,"id":"8fd2dca5","metadata":{"id":"8fd2dca5"},"outputs":[],"source":["### 2. Removing Outliers ####\n","\n","# Using the IQR method to remove outliers AnnualPremium\n","Q1 = df['AnnualPremium'].quantile(0.25)\n","Q3 = df['AnnualPremium'].quantile(0.75)\n","IQR = Q3 - Q1\n","df = df[~((df['AnnualPremium'] < (Q1 - 1.5 * IQR)) | (df['AnnualPremium'] > (Q3 + 1.5 * IQR)))]\n","\n","# Using the IQR method to remove outliers Age\n","Q1 = df['Age'].quantile(0.25)\n","Q3 = df['Age'].quantile(0.75)\n","IQR = Q3 - Q1\n","df = df[~((df['Age'] < (Q1 - 1.5 * IQR)) | (df['Age'] > (Q3 + 1.5 * IQR)))]\n","\n","## Check outliers ##\n","_, ax = plt.subplots()\n","\n","bp = ax.boxplot(df[\"AnnualPremium\"])\n","outliers = [f.get_ydata() for f in bp[\"fliers\"]]\n","outlier_count = len(outliers[0])\n","\n","print(f\"Number of outliers: {outlier_count}\")\n"]},{"cell_type":"markdown","id":"cc17b746","metadata":{"id":"cc17b746"},"source":["### 3.2 Feature scaling numerical variables"]},{"cell_type":"code","execution_count":null,"id":"829ec61b","metadata":{"id":"829ec61b"},"outputs":[],"source":["from sklearn.preprocessing import MinMaxScaler\n","\n","# Initialize the MinMaxScaler\n","scaler = MinMaxScaler()\n","\n","# Fit and transform the AnnualPremium column\n","scaler.fit(df[['AnnualPremium']])\n","df['AnnualPremium'] = scaler.transform(df[['AnnualPremium']])\n","\n","# # Fit and transform the SalesChannelID column\n","# df['SalesChannelID'] = scaler.fit_transform(df[['SalesChannelID']])\n","\n","\n","df['Age'] = scaler.fit_transform(df[['Age']])\n","df"]},{"cell_type":"markdown","id":"ba7c7a36","metadata":{"id":"ba7c7a36"},"source":["## 4. Encoding Features"]},{"cell_type":"markdown","id":"f311d2d1","metadata":{"id":"f311d2d1"},"source":["### 4.1 Encoding: Ordinal Encode \"VehicleAge\""]},{"cell_type":"code","execution_count":null,"id":"2a0d2fcb","metadata":{"id":"2a0d2fcb"},"outputs":[],"source":["# Using mapping to encode VehicleAge\n","\n","# Mapping for VehicleAge\n","df['VehicleAge'] = df['VehicleAge'].map({'< 1 Year': 0, '1-2 Year': 1, '> 2 Years': 2})\n","\n","df\n"]},{"cell_type":"markdown","id":"c0470c8e","metadata":{"id":"c0470c8e"},"source":["### 4.2 One-hot encode categorical values"]},{"cell_type":"code","execution_count":null,"id":"6033b52d","metadata":{"id":"6033b52d"},"outputs":[],"source":["# One-hot encode\n","df = pd.get_dummies(df, columns=['Gender'])\n","df = pd.get_dummies(df, columns=['Switch'])\n","df = pd.get_dummies(df, columns=['PastAccident'])\n","df"]},{"cell_type":"markdown","id":"e68118be","metadata":{"id":"e68118be"},"source":["## 5. Feature Selection"]},{"cell_type":"markdown","id":"a1c78353","metadata":{"id":"a1c78353"},"source":["### 5.1 Chi squared test for categorical features"]},{"cell_type":"code","execution_count":null,"id":"ccf3d925","metadata":{"id":"ccf3d925"},"outputs":[],"source":["from sklearn.feature_selection import chi2\n","\n","# Select all the features except the target variable 'Result'\n","# and the numerical features\n","X = df.drop(columns=['Result', 'Age', 'AnnualPremium', 'DaysSinceCreated'])\n","\n","# Select the target variable 'Result'\n","y = df['Result']\n","\n","# Calculate the chi squared test for each feature\n","chi2_scores, p_values = chi2(X, y)\n","\n","# Create a list of tuples containing the feature, score, and p-value\n","feature_scores = [(feature, score, p_value) for feature, score, p_value in zip(X.columns, chi2_scores, p_values)]\n","\n","# Sort the list of tuples by the chi squared score in descending order\n","feature_scores.sort(key=lambda x: x[1], reverse=True)\n","\n","# Print the features in order of highest chi squared score to lowest\n","for feature, score, p_value in feature_scores:\n","    print(f\"{feature}: ----Chi-score: {score:.2f} ---- p-value: {p_value:.2f}\")\n","\n","\n"]},{"cell_type":"markdown","id":"8c82904d","metadata":{"id":"8c82904d"},"source":["### 5.2 Pearson Correlation for numerical features"]},{"cell_type":"code","execution_count":null,"id":"ab1358e1","metadata":{"scrolled":true,"id":"ab1358e1"},"outputs":[],"source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(5, 3))\n","\n","# Calculate the Pearson correlation coefficients for all the numeric features\n","corr = df[['Age', 'AnnualPremium', 'DaysSinceCreated']].corr(method='pearson', numeric_only=True)\n","\n","\n","# Plot the correlation matrix using a heatmap\n","sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns, annot=True)\n","\n","# Show the plot\n","\n","\n","plt.show()"]},{"cell_type":"markdown","id":"32ce4845","metadata":{"id":"32ce4845"},"source":["### 5.3 Feature selection: dropping irrelevant features based on Chi and Pearson"]},{"cell_type":"code","execution_count":null,"id":"25d7782c","metadata":{"id":"25d7782c"},"outputs":[],"source":["df = df.drop('DaysSinceCreated', axis=1)\n","# df = df.drop('RegionID', axis=1)\n","# We drop HasDrivingLicense as they have majority of identical value\n","df = df.drop('HasDrivingLicense', axis=1)\n","\n","df"]},{"cell_type":"code","execution_count":null,"id":"d2094aa1","metadata":{"id":"d2094aa1"},"outputs":[],"source":["df"]},{"cell_type":"markdown","id":"dd55b2ea","metadata":{"id":"dd55b2ea"},"source":["## 6. Handling imbalanced data"]},{"cell_type":"markdown","id":"eb2f61f6","metadata":{"id":"eb2f61f6"},"source":["###  6.0 Splitting data into train and test set"]},{"cell_type":"code","execution_count":null,"id":"176c228d","metadata":{"id":"176c228d"},"outputs":[],"source":["# Separate the features and target\n","X = df.drop('Result', axis=1)\n","y = df['Result']\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0, stratify=y)\n","\n","X_train"]},{"cell_type":"markdown","id":"fb7f94b8","metadata":{"id":"fb7f94b8"},"source":["### 6.2 SMOTEENN"]},{"cell_type":"code","execution_count":null,"id":"3ce5a0fc","metadata":{"id":"3ce5a0fc"},"outputs":[],"source":["import pandas as pd\n","from imblearn.combine import SMOTEENN\n","\n","\n","# Create the SMOTEENN object\n","smote_enn = SMOTEENN(random_state=0)\n","\n","# Fit the SMOTEENN object on the data\n","X_sampledEEN, y_sampledEEN = smote_enn.fit_resample(X_train, y_train)\n","\n","# Check the balance of the resampled data\n","print(y_sampledEEN.value_counts())"]},{"cell_type":"markdown","id":"fb74b155","metadata":{"id":"fb74b155"},"source":["### 6.3 SMOTENC"]},{"cell_type":"code","execution_count":null,"id":"b7cfa82f","metadata":{"id":"b7cfa82f"},"outputs":[],"source":["### 6. Handling imbalance --- SMOTENC ###\n","\n","from imblearn.over_sampling import SMOTENC\n","\n","# Assume that X is the input features and y is the target variable\n","# Assume that X has both numeric and categorical features\n","\n","# Select the indices of the categorical and numeric features\n","cat_idx = [1, 2, 4, 5, 6, 7, 8, 9, 10]\n","num_idx = [0, 3]\n","\n","# Oversample the minority class using SMOTENC\n","smotenc = SMOTENC(categorical_features=cat_idx, random_state=42)\n","X_resampledSMOTENC, y_resampledSMOTENC = smotenc.fit_resample(X_train, y_train)\n","\n","\n","\n","print(y_resampledSMOTENC.value_counts())"]},{"cell_type":"markdown","id":"0fef02c0","metadata":{"id":"0fef02c0"},"source":["# Model Implementation"]},{"cell_type":"markdown","id":"e41aabc9","metadata":{"id":"e41aabc9"},"source":["## 1. XGBoost"]},{"cell_type":"markdown","id":"c6ffbe8f","metadata":{"id":"c6ffbe8f"},"source":["### 1.1 Hyperparameter Optimization using RandomizedSearchCV"]},{"cell_type":"code","execution_count":null,"id":"d41592c6","metadata":{"id":"d41592c6"},"outputs":[],"source":["import xgboost as xgb\n","from sklearn.model_selection import RandomizedSearchCV\n","from sklearn.model_selection import RepeatedStratifiedKFold\n","import random\n","\n","# Define the parameters to search\n","parameters = {'max_depth': [3, 5, 7, 10],\n","              'learning_rate': [0.1, 0.5, 1],\n","              'subsample': [0.5, 0.8, 1.0],\n","              'colsample_bytree': [0.5, 0.8, 1.0],\n","              'reg_alpha': [0, 0.1, 0.5, 1],\n","              'reg_lambda': [0, 0.1, 0.5, 1],\n","              'n_estimators': [10, 20]}\n","\n","# Create the XGBoost model\n","xgb_model = xgb.XGBClassifier()\n","\n","cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n","\n","# Create the random search object\n","random_search = RandomizedSearchCV(estimator=xgb_model,\n","                                   param_distributions=parameters, cv=cv, n_iter=10, scoring='f1', random_state=42)\n","\n","# Fit the random search to the data\n","random_search.fit(X_train, y_train)\n","\n","# Print the best parameters\n","print(random_search.best_params_)"]},{"cell_type":"markdown","id":"07c6da5f","metadata":{"id":"07c6da5f"},"source":["### 1.2 Model implementation"]},{"cell_type":"code","execution_count":null,"id":"69d1ec14","metadata":{"id":"69d1ec14"},"outputs":[],"source":["import xgboost as xgb\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import classification_report\n","from sklearn.model_selection import cross_val_score\n","# Assume that X is the input features and y is the target variable\n","\n","# Calculate the class imbalance ratio\n","negative_count = sum(y_train == 0)\n","positive_count = sum(y_train == 1)\n","ratio = negative_count / positive_count\n","\n","# Create an XGBoost classifier\n","clf = xgb.XGBClassifier(subsample=0.1, reg_lambda=0.1, reg_alpha=1,\n","                        max_depth=7, learning_rate=0.1, colsample_bytree=0.8,\n","                        n_estimators=10, scale_pos_weight = ratio)\n","# Train the classifier\n","clf.fit(X_train, y_train)\n","\n","# Predict the class labels for new data\n","y_predict = clf.predict(X_test)\n","\n","\n","# Perform K-Fold cross-validation with K=5\n","scores = cross_val_score(clf, X_train, y_train, cv=5, scoring = 'roc_auc')\n","\n","# Print the score values\n","print('ROC_AUC Scores: ' + str(scores))\n","# Print the mean and standard deviation of the scores\n","print(f'Mean score: {scores.mean():.2f}')\n","\n","# Metric scores\n","accuracy = accuracy_score(y_test, y_predict)\n","print(f'Accuracy: {accuracy:.2f}')\n","classification_random = (classification_report(y_test, y_predict))\n","print(classification_random)\n","\n","\n","\n","#(subsample=1.0, reg_lambda=0.1, reg_alpha=1,\n","                        #max_depth=7, learning_rate=0.1, colsample_bytree=0.8,\n","                        #n_estimators=3, scale_pos_weight = ratio) -- BEST PERFORMANCE\n","\n","\n","#{'subsample': 0.5, 'reg_lambda': 0.1, 'reg_alpha': 1,\n","#'n_estimators': 10, 'max_depth': 10, 'learning_rate': 1, 'colsample_bytree': 0.5}"]},{"cell_type":"markdown","id":"5f48e013","metadata":{"id":"5f48e013"},"source":["### 1.3 Performance Evaluation"]},{"cell_type":"code","execution_count":null,"id":"100adc1e","metadata":{"id":"100adc1e"},"outputs":[],"source":["from sklearn.metrics import precision_recall_curve, auc\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import cohen_kappa_score\n","\n","# Compute precision and recall, and compute AUC of the precision-recall curve\n","precision, recall, thresholds = precision_recall_curve(y_test, y_predict)\n","pr_auc = auc(recall, precision)\n","\n","# Plot the precision-recall curve\n","plt.plot(recall, precision, label='Precision-Recall curve')\n","plt.xlabel('Recall')\n","plt.ylabel('Precision')\n","plt.title('Precision-Recall curve')\n","plt.show()\n","\n","# Print the AUC\n","print('PR-AUC: {:.3f}'.format(pr_auc))\n","from sklearn.metrics import roc_auc_score\n","\n","\n","from sklearn.metrics import roc_curve, auc\n","import matplotlib.pyplot as plt\n","fpr, tpr, thresholds = roc_curve(y_test, y_predict)\n","roc_auc = auc(fpr, tpr)\n","\n","\n","\n","\n","plt.figure()\n","plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n","plt.plot([0, 1], [0, 1], 'k--')\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('Receiver operating characteristic curve')\n","plt.legend(loc=\"lower right\")\n","plt.show()\n","\n","roc_auc = roc_auc_score (y_test, y_predict)\n","print('ROC-AUC: {:.3f}'.format(roc_auc))\n","\n","\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix\n","\n","# Calculate the confusion matrix\n","cm = confusion_matrix(y_test, y_predict)\n","\n","# Plot the confusion matrix as a heatmap\n","plt.imshow(cm, cmap='Blues')\n","\n","# Add labels to the plot\n","plt.xlabel('Predicted label')\n","plt.ylabel('True label')\n","\n","# Add a colorbar\n","plt.colorbar()\n","\n","# Add the numbers to the plot\n","threshold = cm.max() / 2.0\n","for i in range(cm.shape[0]):\n","    for j in range(cm.shape[1]):\n","        plt.text(j, i, cm[i, j],\n","                 horizontalalignment='center',\n","                 color='white' if cm[i, j] > threshold else 'black')\n","\n","# Show the plot\n","plt.show()\n","\n","kappa = cohen_kappa_score(y_test, y_predict)\n","\n","print(kappa)"]},{"cell_type":"markdown","id":"52df416b","metadata":{"id":"52df416b"},"source":["## 2. KNN"]},{"cell_type":"markdown","id":"5b3d54ee","metadata":{"id":"5b3d54ee"},"source":["### 2.1 Hyperparameter Optimization using RandomizedSearchCV"]},{"cell_type":"code","execution_count":null,"id":"2bcb35e3","metadata":{"id":"2bcb35e3"},"outputs":[],"source":["from sklearn.model_selection import RandomizedSearchCV\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","# Create a KNN classifier\n","knn = KNeighborsClassifier()\n","\n","# Define the grid of hyperparameters to search\n","param_grid = {'n_neighbors': [3, 5, 7, 9, 12, 15]}\n","\n","\n","cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n","\n","# Create a randomized search object using 3-fold cross validation\n","rsearch = RandomizedSearchCV(knn, param_grid, cv=cv, scoring = 'f1')\n","\n","# Fit the randomized search object to your training data\n","rsearch.fit(X_sampledEEN, y_sampledEEN)\n","\n","# Print the best hyperparameters found by the search\n","print(rsearch.best_params_)\n"]},{"cell_type":"markdown","id":"25c161c3","metadata":{"id":"25c161c3"},"source":["### 2.2 Model implementation"]},{"cell_type":"code","execution_count":null,"id":"b0faa0b6","metadata":{"id":"b0faa0b6"},"outputs":[],"source":["from sklearn.model_selection import RepeatedStratifiedKFold\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.model_selection import cross_val_score\n","\n","# Create a KNN classifier\n","knn = KNeighborsClassifier(n_neighbors = 3)\n","\n","# Create the cross-validation object\n","rskf = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=0)\n","\n","# Train and evaluate the model using cross-validation\n","scores = cross_val_score(knn, X_resampledSMOTENC, y_resampledSMOTENC, cv=rskf, scoring = 'roc_auc')\n","\n","\n","\n","# Train the classifier\n","knn.fit(X_sampledEEN, y_sampledEEN)\n","\n","# Predict the class labels for new data\n","y_predict = knn.predict(X_test)\n","\n","\n","# Print the mean and standard deviation of the scores\n","print(scores)\n","print(f'Mean score: {scores.mean():.2f}')\n","print(f'Standard deviation: {scores.std():.2f}')\n","\n","\n","\n","\n","\n","# Metric scores\n","print('\\n')\n","classification_random = (classification_report(y_test, y_predict))\n","print(classification_random)"]},{"cell_type":"markdown","id":"fb0f1271","metadata":{"id":"fb0f1271"},"source":["### 2.3 Performance Evaluation"]},{"cell_type":"code","execution_count":null,"id":"8d2a8c00","metadata":{"scrolled":false,"id":"8d2a8c00"},"outputs":[],"source":["from sklearn.metrics import precision_recall_curve, auc\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import cohen_kappa_score\n","\n","# Compute precision and recall, and compute AUC of the precision-recall curve\n","precision, recall, thresholds = precision_recall_curve(y_test, y_predict)\n","pr_auc = auc(recall, precision)\n","\n","# Plot the precision-recall curve\n","plt.plot(recall, precision, label='Precision-Recall curve')\n","plt.xlabel('Recall')\n","plt.ylabel('Precision')\n","plt.title('Precision-Recall curve')\n","plt.show()\n","\n","# Print the AUC\n","print('PR-AUC: {:.3f}'.format(pr_auc))\n","from sklearn.metrics import roc_auc_score\n","\n","\n","from sklearn.metrics import roc_curve, auc\n","import matplotlib.pyplot as plt\n","fpr, tpr, thresholds = roc_curve(y_test, y_predict)\n","roc_auc = auc(fpr, tpr)\n","\n","\n","\n","\n","plt.figure()\n","plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n","plt.plot([0, 1], [0, 1], 'k--')\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('Receiver operating characteristic curve')\n","plt.legend(loc=\"lower right\")\n","plt.show()\n","\n","roc_auc = roc_auc_score (y_test, y_predict)\n","print('ROC-AUC: {:.3f}'.format(roc_auc))\n","\n","\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix\n","\n","# Calculate the confusion matrix\n","cm = confusion_matrix(y_test, y_predict)\n","\n","# Plot the confusion matrix as a heatmap\n","plt.imshow(cm, cmap='Blues')\n","\n","# Add labels to the plot\n","plt.xlabel('Predicted label')\n","plt.ylabel('True label')\n","\n","# Add a colorbar\n","plt.colorbar()\n","\n","# Add the numbers to the plot\n","threshold = cm.max() / 2.0\n","for i in range(cm.shape[0]):\n","    for j in range(cm.shape[1]):\n","        plt.text(j, i, cm[i, j],\n","                 horizontalalignment='center',\n","                 color='white' if cm[i, j] > threshold else 'black')\n","\n","# Show the plot\n","plt.show()\n","\n","kappa = cohen_kappa_score(y_test, y_predict)\n","\n","print(kappa)"]},{"cell_type":"markdown","id":"fb0c2785","metadata":{"id":"fb0c2785"},"source":["## 3. Random Forest"]},{"cell_type":"markdown","id":"167fd875","metadata":{"id":"167fd875"},"source":["### 3.1 Hyperparameter Optimization using RandomizedSearchCV"]},{"cell_type":"code","execution_count":null,"id":"d78b0400","metadata":{"id":"d78b0400"},"outputs":[],"source":["from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import RandomizedSearchCV\n","from sklearn.model_selection import RepeatedStratifiedKFold\n","\n","# Define the parameter space that you want to search over\n","param_grid = {\n","    'n_estimators': [10, 50, 100],\n","    'max_depth': [None, 2, 7, 13],\n","    'min_samples_split': [1, 3, 8],\n","    'min_samples_leaf': [1, 3, 6],\n","    'max_features': [2, 4, 7]\n","}\n","\n","# Create a random forest classifier\n","rfc = RandomForestClassifier()\n","\n","cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n","\n","# Create a randomized search object using 3-fold cross validation\n","rsearch = RandomizedSearchCV(rfc, param_grid, cv=cv, scoring = 'f1')\n","\n","# Fit the randomized search object to your training data\n","rsearch.fit(X_sampledEEN, y_sampledEEN)\n","\n","# Print the best hyperparameters found by the search\n","print(rsearch.best_params_)\n"]},{"cell_type":"markdown","id":"c2a87549","metadata":{"id":"c2a87549"},"source":["### 3.2 Model implementation"]},{"cell_type":"code","execution_count":null,"id":"4a9e72b1","metadata":{"id":"4a9e72b1"},"outputs":[],"source":["### Model Implemenation: RandomForestClassifier ###\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import cross_val_score\n","\n","random_forest = RandomForestClassifier(n_estimators = 10, max_features = 2, min_samples_leaf = 6, min_samples_split = 3,\n","                                       criterion = 'gini', random_state = 0, max_depth =None)\n","\n","random_forest.fit(X_sampledEEN, y_sampledEEN)\n","y_predict = random_forest.predict(X_test)\n","\n","\n","\n","# Perform K-Fold cross-validation with K=5\n","scores = cross_val_score(clf, X_train, y_train, cv=5, scoring = 'roc_auc')\n","\n","# Print the score values\n","print('ROC_AUC Scores: ' + str(scores))\n","# Print the mean and standard deviation of the scores\n","print(f'Mean score: {scores.mean():.2f}')\n","\n","\n","# Metric scores\n","print('\\n')\n","classification_random = (classification_report(y_test, y_predict))\n","print(classification_random)"]},{"cell_type":"markdown","id":"d3951d38","metadata":{"id":"d3951d38"},"source":["### 3.3 Performance Evaluation"]},{"cell_type":"code","execution_count":null,"id":"21c50bef","metadata":{"id":"21c50bef"},"outputs":[],"source":["from sklearn.metrics import precision_recall_curve, auc\n","import matplotlib.pyplot as plt\n","\n","# Compute precision and recall, and compute AUC of the precision-recall curve\n","precision, recall, thresholds = precision_recall_curve(y_test, y_predict)\n","pr_auc = auc(recall, precision)\n","\n","# Plot the precision-recall curve\n","plt.plot(recall, precision, label='Precision-Recall curve')\n","plt.xlabel('Recall')\n","plt.ylabel('Precision')\n","plt.title('Precision-Recall curve')\n","plt.show()\n","\n","# Print the AUC\n","print('PR-AUC: {:.3f}'.format(pr_auc))\n","from sklearn.metrics import roc_auc_score\n","\n","\n","from sklearn.metrics import roc_curve, auc\n","import matplotlib.pyplot as plt\n","fpr, tpr, thresholds = roc_curve(y_test, y_predict)\n","roc_auc = auc(fpr, tpr)\n","\n","\n","\n","\n","plt.figure()\n","plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n","plt.plot([0, 1], [0, 1], 'k--')\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('Receiver operating characteristic curve')\n","plt.legend(loc=\"lower right\")\n","plt.show()\n","\n","roc_auc = roc_auc_score (y_test, y_predict)\n","print('ROC-AUC: {:.3f}'.format(roc_auc))\n","\n","\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix\n","\n","# Calculate the confusion matrix\n","cm = confusion_matrix(y_test, y_predict)\n","\n","# Plot the confusion matrix as a heatmap\n","plt.imshow(cm, cmap='Blues')\n","\n","# Add labels to the plot\n","plt.xlabel('Predicted label')\n","plt.ylabel('True label')\n","\n","# Add a colorbar\n","plt.colorbar()\n","\n","# Add the numbers to the plot\n","threshold = cm.max() / 2.0\n","for i in range(cm.shape[0]):\n","    for j in range(cm.shape[1]):\n","        plt.text(j, i, cm[i, j],\n","                 horizontalalignment='center',\n","                 color='white' if cm[i, j] > threshold else 'black')\n","\n","# Show the plot\n","plt.show()\n","\n","kappa = cohen_kappa_score(y_test, y_predict)\n","\n","print(kappa)\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}